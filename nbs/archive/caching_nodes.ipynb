{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching Nodes with Hamilton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loaders\n",
    "# When developing, we would likely want to cache our data loaders because of latencies in loading data from networked sources or slow disks.\n",
    "# Functions marked by `tag(cache=\"SERIALIZATION_FORMAT\")` are automatically cached by the CachingGraphAdapter (discussed later).\n",
    "\n",
    "from hamilton.function_modifiers import tag\n",
    "\n",
    "spends_data = [10, 10, 20, 40, 40, 50]\n",
    "signups_data = [1, 10, 50, 100, 200, 400]\n",
    "\n",
    "@tag(cache=\"parquet\")\n",
    "def spend() -> pd.Series:\n",
    "    \"\"\"Emulates potentially expensive data extraction.\"\"\"\n",
    "    return pd.Series(spends_data)\n",
    "\n",
    "\n",
    "@tag(cache=\"parquet\")\n",
    "def signups() -> pd.Series:\n",
    "    \"\"\"Emulates potentially expensive data extraction.\"\"\"\n",
    "    return pd.Series(signups_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions holding bussiness logic\n",
    "\n",
    "\n",
    "def avg_3wk_spend(spend: pd.Series) -> pd.Series:\n",
    "    \"\"\"Rolling 3 week average spend.\"\"\"\n",
    "    return spend.rolling(3).mean()\n",
    "\n",
    "\n",
    "def spend_per_signup(spend: pd.Series, signups: pd.Series) -> pd.Series:\n",
    "    \"\"\"The cost per signup in relation to spend.\"\"\"\n",
    "    return spend / signups\n",
    "\n",
    "\n",
    "def spend_mean(spend: pd.Series) -> float:\n",
    "    \"\"\"Shows function creating a scalar. In this case it computes the mean of the entire column.\"\"\"\n",
    "    return spend.mean()\n",
    "\n",
    "\n",
    "def spend_zero_mean(spend: pd.Series, spend_mean: float) -> pd.Series:\n",
    "    \"\"\"Shows function that takes a scalar. In this case to zero mean spend.\"\"\"\n",
    "    return spend - spend_mean\n",
    "\n",
    "\n",
    "def spend_std_dev(spend: pd.Series) -> float:\n",
    "    \"\"\"Function that computes the standard deviation of the spend column.\"\"\"\n",
    "    return spend.std()\n",
    "\n",
    "\n",
    "def spend_zero_mean_unit_variance(spend_zero_mean: pd.Series, spend_std_dev: float) -> pd.Series:\n",
    "    \"\"\"Function showing one way to make spend have zero mean and unit variance.\"\"\"\n",
    "    return spend_zero_mean / spend_std_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place the functions into a temporary module -- the idea is that this should house a curated set of functions.\n",
    "# Don't be afraid to make multiple of them -- however we'd advise you to not use this method for production.\n",
    "# Also note, that using a temporary function module does not work for scaling onto Ray, Dask, or Pandas on Spark.\n",
    "from hamilton import ad_hoc_utils\n",
    "\n",
    "\n",
    "data_loaders = ad_hoc_utils.create_temporary_module(\n",
    "    spend, signups, module_name=\"data_loaders\"\n",
    ")\n",
    "\n",
    "business_logic = ad_hoc_utils.create_temporary_module(\n",
    "    avg_3wk_spend, \n",
    "    spend_per_signup,\n",
    "    spend_mean,\n",
    "    spend_zero_mean,\n",
    "    spend_std_dev,\n",
    "    spend_zero_mean_unit_variance, \n",
    "    module_name=\"business_logic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamilton import base, driver\n",
    "from hamilton.experimental import h_cache\n",
    "import pathlib\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Hamilton collects completely anonymous data about usage. This will help us improve Hamilton over time. See https://github.com/dagworks-inc/hamilton#usage-analytics--data-privacy for details.\n",
      "Node spend encountered an error\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/execution/graph_functions.py\", line 147, in dfs_traverse\n",
      "    value = adapter.execute_node(node_, kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py\", line 330, in execute_node\n",
      "    self._write_cache(cache_format, result, filepath, node.name)\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py\", line 294, in _write_cache\n",
      "    self.writers[fmt](data, filepath, node_name)\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/functools.py\", line 909, in wrapper\n",
      "    return dispatch(args[0].__class__)(*args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py\", line 43, in write_parquet\n",
      "    raise NotImplementedError(f\"No parquet writer for type {type(data)} registered.\")\n",
      "NotImplementedError: No parquet writer for type <class 'pandas.core.series.Series'> registered.\n",
      "-------------------------------------------------------------------\n",
      "Oh no an error! Need help with Hamilton?\n",
      "Join our slack and ask for help! https://join.slack.com/t/hamilton-opensource/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "No parquet writer for type <class 'pandas.core.series.Series'> registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m      9\u001b[0m dr \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mDriver(initial_columns, business_logic, data_loaders, adapter\u001b[38;5;241m=\u001b[39madapter)\n\u001b[1;32m     10\u001b[0m output_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignups\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspend_zero_mean_unit_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mto_string())\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:410\u001b[0m, in \u001b[0;36mDriver.execute\u001b[0;34m(self, final_vars, overrides, display_graph, inputs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(SLACK_ERROR_MESSAGE)\n\u001b[1;32m    409\u001b[0m     error \u001b[38;5;241m=\u001b[39m telemetry\u001b[38;5;241m.\u001b[39msanitize_error(\u001b[38;5;241m*\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:403\u001b[0m, in \u001b[0;36mDriver.execute\u001b[0;34m(self, final_vars, overrides, display_graph, inputs)\u001b[0m\n\u001b[1;32m    401\u001b[0m _final_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_final_vars(final_vars)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_final_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mbuild_result(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs)\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:498\u001b[0m, in \u001b[0;36mDriver.raw_execute\u001b[0;34m(self, final_vars, overrides, display_graph, inputs)\u001b[0m\n\u001b[1;32m    496\u001b[0m all_nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;241m|\u001b[39m user_nodes\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_executor\u001b[38;5;241m.\u001b[39mvalidate(\u001b[38;5;28mlist\u001b[39m(all_nodes))\n\u001b[0;32m--> 498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:162\u001b[0m, in \u001b[0;36mDefaultGraphExecutor.execute\u001b[0;34m(self, fg, final_vars, overrides, inputs)\u001b[0m\n\u001b[1;32m    160\u001b[0m memoized_computation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()  \u001b[38;5;66;03m# memoized storage\u001b[39;00m\n\u001b[1;32m    161\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [fg\u001b[38;5;241m.\u001b[39mnodes[node_name] \u001b[38;5;28;01mfor\u001b[39;00m node_name \u001b[38;5;129;01min\u001b[39;00m final_vars]\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemoized_computation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    164\u001b[0m     final_var: memoized_computation[final_var] \u001b[38;5;28;01mfor\u001b[39;00m final_var \u001b[38;5;129;01min\u001b[39;00m final_vars\n\u001b[1;32m    165\u001b[0m }  \u001b[38;5;66;03m# only want request variables in df.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m memoized_computation  \u001b[38;5;66;03m# trying to cleanup some memory\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/graph.py:556\u001b[0m, in \u001b[0;36mFunctionGraph.execute\u001b[0;34m(self, nodes, computed, overrides, inputs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    555\u001b[0m inputs \u001b[38;5;241m=\u001b[39m combine_config_and_inputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, inputs)\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecute_subdag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/execution/graph_functions.py:177\u001b[0m, in \u001b[0;36mexecute_subdag\u001b[0;34m(nodes, inputs, adapter, computed, overrides)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_var_node\u001b[38;5;241m.\u001b[39muser_defined:\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;66;03m# from the top level, we don't know if this UserInput is required. So mark as optional.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m         dep_type \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mDependencyType\u001b[38;5;241m.\u001b[39mOPTIONAL\n\u001b[0;32m--> 177\u001b[0m     \u001b[43mdfs_traverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_var_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m computed\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/execution/graph_functions.py:147\u001b[0m, in \u001b[0;36mexecute_subdag.<locals>.dfs_traverse\u001b[0;34m(node_, dependency_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m         kwargs[dependency\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m computed[dependency\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m encountered an error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py:330\u001b[0m, in \u001b[0;36mCachingGraphAdapter.execute_node\u001b[0;34m(self, node, kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m result \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    323\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting cache for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m     node\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m     cache_format,\n\u001b[1;32m    329\u001b[0m )\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputed_nodes\u001b[38;5;241m.\u001b[39madd(node\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py:294\u001b[0m, in \u001b[0;36mCachingGraphAdapter._write_cache\u001b[0;34m(self, fmt, data, filepath, node_name)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m, fmt: \u001b[38;5;28mstr\u001b[39m, data: Any, filepath: \u001b[38;5;28mstr\u001b[39m, node_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_format(fmt)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py:43\u001b[0m, in \u001b[0;36mwrite_parquet\u001b[0;34m(data, filepath, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_parquet\u001b[39m(data: \u001b[38;5;28mobject\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Writes data to a parquet file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo parquet writer for type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registered.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No parquet writer for type <class 'pandas.core.series.Series'> registered."
     ]
    }
   ],
   "source": [
    "# This is empty, we get the data from the data_loaders module\n",
    "initial_columns = {}\n",
    "\n",
    "# Initialise the cache directory\n",
    "cache_path = \"tmp\"\n",
    "pathlib.Path(cache_path).mkdir(exist_ok=True)\n",
    "\n",
    "adapter = h_cache.CachingGraphAdapter(cache_path, base.PandasDataFrameResult())\n",
    "dr = driver.Driver(initial_columns, business_logic, data_loaders, adapter=adapter)\n",
    "output_columns = [\n",
    "    \"spend\",\n",
    "    \"signups\",\n",
    "    \"avg_3wk_spend\",\n",
    "    \"spend_per_signup\",\n",
    "    \"spend_zero_mean_unit_variance\",\n",
    "]\n",
    "\n",
    "df = dr.execute(output_columns)\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets change the source values for our data loaders. \n",
    "\n",
    "spends_data = [i * 1000 for i in spends_data]\n",
    "signups_data = [i * 1000 for i in spends_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node spend encountered an error\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/execution/graph_functions.py\", line 147, in dfs_traverse\n",
      "    value = adapter.execute_node(node_, kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py\", line 330, in execute_node\n",
      "    self._write_cache(cache_format, result, filepath, node.name)\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py\", line 294, in _write_cache\n",
      "    self.writers[fmt](data, filepath, node_name)\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/functools.py\", line 909, in wrapper\n",
      "    return dispatch(args[0].__class__)(*args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giladrubin/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py\", line 43, in write_parquet\n",
      "    raise NotImplementedError(f\"No parquet writer for type {type(data)} registered.\")\n",
      "NotImplementedError: No parquet writer for type <class 'pandas.core.series.Series'> registered.\n",
      "-------------------------------------------------------------------\n",
      "Oh no an error! Need help with Hamilton?\n",
      "Join our slack and ask for help! https://join.slack.com/t/hamilton-opensource/shared_invite/zt-1bjs72asx-wcUTgH7q7QX1igiQ5bbdcg\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "No parquet writer for type <class 'pandas.core.series.Series'> registered.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m dr \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mDriver(initial_columns, business_logic, data_loaders, adapter\u001b[38;5;241m=\u001b[39madapter)\n\u001b[1;32m     11\u001b[0m output_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspend\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msignups\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspend_zero_mean_unit_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m ]\n\u001b[0;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mto_string())\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:410\u001b[0m, in \u001b[0;36mDriver.execute\u001b[0;34m(self, final_vars, overrides, display_graph, inputs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(SLACK_ERROR_MESSAGE)\n\u001b[1;32m    409\u001b[0m     error \u001b[38;5;241m=\u001b[39m telemetry\u001b[38;5;241m.\u001b[39msanitize_error(\u001b[38;5;241m*\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info())\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:403\u001b[0m, in \u001b[0;36mDriver.execute\u001b[0;34m(self, final_vars, overrides, display_graph, inputs)\u001b[0m\n\u001b[1;32m    401\u001b[0m _final_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_final_vars(final_vars)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_final_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mbuild_result(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs)\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:498\u001b[0m, in \u001b[0;36mDriver.raw_execute\u001b[0;34m(self, final_vars, overrides, display_graph, inputs)\u001b[0m\n\u001b[1;32m    496\u001b[0m all_nodes \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;241m|\u001b[39m user_nodes\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph_executor\u001b[38;5;241m.\u001b[39mvalidate(\u001b[38;5;28mlist\u001b[39m(all_nodes))\n\u001b[0;32m--> 498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/driver.py:162\u001b[0m, in \u001b[0;36mDefaultGraphExecutor.execute\u001b[0;34m(self, fg, final_vars, overrides, inputs)\u001b[0m\n\u001b[1;32m    160\u001b[0m memoized_computation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()  \u001b[38;5;66;03m# memoized storage\u001b[39;00m\n\u001b[1;32m    161\u001b[0m nodes \u001b[38;5;241m=\u001b[39m [fg\u001b[38;5;241m.\u001b[39mnodes[node_name] \u001b[38;5;28;01mfor\u001b[39;00m node_name \u001b[38;5;129;01min\u001b[39;00m final_vars]\n\u001b[0;32m--> 162\u001b[0m \u001b[43mfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemoized_computation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    164\u001b[0m     final_var: memoized_computation[final_var] \u001b[38;5;28;01mfor\u001b[39;00m final_var \u001b[38;5;129;01min\u001b[39;00m final_vars\n\u001b[1;32m    165\u001b[0m }  \u001b[38;5;66;03m# only want request variables in df.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m memoized_computation  \u001b[38;5;66;03m# trying to cleanup some memory\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/graph.py:556\u001b[0m, in \u001b[0;36mFunctionGraph.execute\u001b[0;34m(self, nodes, computed, overrides, inputs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    555\u001b[0m inputs \u001b[38;5;241m=\u001b[39m combine_config_and_inputs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, inputs)\n\u001b[0;32m--> 556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecute_subdag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43madapter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/execution/graph_functions.py:177\u001b[0m, in \u001b[0;36mexecute_subdag\u001b[0;34m(nodes, inputs, adapter, computed, overrides)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_var_node\u001b[38;5;241m.\u001b[39muser_defined:\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;66;03m# from the top level, we don't know if this UserInput is required. So mark as optional.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m         dep_type \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mDependencyType\u001b[38;5;241m.\u001b[39mOPTIONAL\n\u001b[0;32m--> 177\u001b[0m     \u001b[43mdfs_traverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_var_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdep_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m computed\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/execution/graph_functions.py:147\u001b[0m, in \u001b[0;36mexecute_subdag.<locals>.dfs_traverse\u001b[0;34m(node_, dependency_type)\u001b[0m\n\u001b[1;32m    145\u001b[0m         kwargs[dependency\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m computed[dependency\u001b[38;5;241m.\u001b[39mname]\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m encountered an error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py:330\u001b[0m, in \u001b[0;36mCachingGraphAdapter.execute_node\u001b[0;34m(self, node, kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m result \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    323\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriting cache for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    325\u001b[0m     node\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    328\u001b[0m     cache_format,\n\u001b[1;32m    329\u001b[0m )\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputed_nodes\u001b[38;5;241m.\u001b[39madd(node\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py:294\u001b[0m, in \u001b[0;36mCachingGraphAdapter._write_cache\u001b[0;34m(self, fmt, data, filepath, node_name)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_write_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m, fmt: \u001b[38;5;28mstr\u001b[39m, data: Any, filepath: \u001b[38;5;28mstr\u001b[39m, node_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_format(fmt)\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriters\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/rent/lib/python3.11/site-packages/hamilton/experimental/h_cache.py:43\u001b[0m, in \u001b[0;36mwrite_parquet\u001b[0;34m(data, filepath, name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;129m@singledispatch\u001b[39m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_parquet\u001b[39m(data: \u001b[38;5;28mobject\u001b[39m, filepath: \u001b[38;5;28mstr\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Writes data to a parquet file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo parquet writer for type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registered.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: No parquet writer for type <class 'pandas.core.series.Series'> registered."
     ]
    }
   ],
   "source": [
    "# Since the data loaders are cached, they should continue returning the old values.\n",
    "\n",
    "spends_data = [i * 1000 for i in spends_data]\n",
    "signups_data = [i * 1000 for i in spends_data]\n",
    "\n",
    "# CachingGraphAdapter handles the actual caching during exection.\n",
    "adapter = h_cache.CachingGraphAdapter(cache_path, base.PandasDataFrameResult())\n",
    "\n",
    "# Hamilton caches are valid accross new instances of the driver. \n",
    "dr = driver.Driver(initial_columns, business_logic, data_loaders, adapter=adapter)\n",
    "output_columns = [\n",
    "    \"spend\",\n",
    "    \"signups\",\n",
    "    \"avg_3wk_spend\",\n",
    "    \"spend_per_signup\",\n",
    "    \"spend_zero_mean_unit_variance\",\n",
    "]\n",
    "\n",
    "df = dr.execute(output_columns)\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   spend   signups  avg_3wk_spend  spend_per_signup  spend_zero_mean_unit_variance\n",
      "0  10000  10000000            NaN             0.001                      -1.064405\n",
      "1  10000  10000000            NaN             0.001                      -1.064405\n",
      "2  20000  20000000   13333.333333             0.001                      -0.483821\n",
      "3  40000  40000000   23333.333333             0.001                       0.677349\n",
      "4  40000  40000000   33333.333333             0.001                       0.677349\n",
      "5  50000  50000000   43333.333333             0.001                       1.257934\n"
     ]
    }
   ],
   "source": [
    "# Now lets force hamilton to recompute the cached data loaders.\n",
    "\n",
    "adapter = h_cache.CachingGraphAdapter(cache_path, base.PandasDataFrameResult(), force_compute=set([\"spend\", \"signups\"]))\n",
    "dr = driver.Driver(initial_columns, business_logic, data_loaders, adapter=adapter)\n",
    "output_columns = [\n",
    "    \"spend\",\n",
    "    \"signups\",\n",
    "    \"avg_3wk_spend\",\n",
    "    \"spend_per_signup\",\n",
    "    \"spend_zero_mean_unit_variance\",\n",
    "]\n",
    "\n",
    "df = dr.execute(output_columns)\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
